# 补充知识

# spp.

在生物学分类学中，物种名中出现 "spp." 是种的复数形式的缩写。这个缩写来自拉丁文 "species"，在拉丁文中 "spp." 是 "species" 的复数形式，表示多个种。

当一个作者在科学出版物或学术研究中提到多个种时，可以使用 "spp." 来表示多个不同的物种，而不需要逐个列出所有物种的拉丁学名。这通常用于表示一个属（genus）下的多个物种或一个科（family）下的多个属，但具体的物种并没有逐一列出的情况。

例如，假设有一个属名为 "Genus"，而其中包含了 "Species A"、"Species B" 和 "Species C" 这三个物种。当作者提到这个属下的多个物种时，可以简写为 "Genus spp."，表示 "Genus" 属下的所有物种。

# sp.

在生物学分类学中，物种学名中出现 "sp." 是种的缩写。这个缩写来自拉丁文 "species"，表示一种未经鉴定或未经描述的物种。

当一个生物学家在进行研究或进行物种描述时，可能会遇到一些尚未确切鉴定或归类的生物个体。在这种情况下，为了暂时标识这些个体，可以使用 "sp." 缩写，以表示该物种属于某个属（genus），但尚未具体鉴定到物种级别。这样的标识对于暂时记录和描述新物种或未知物种是非常有用的。

举个例子，假设一个生物学家在野外发现了一种新的昆虫，并认为它属于某个已知的属（genus），但尚未确定具体的种级别分类。在这种情况下，可以使用 "genus sp." 来表示这个新物种。

# cf.

在生物学分类学中，物种学名中出现 "cf." 表示一种推测或猜测的状态。这个缩写来自拉丁文 "confer"，意思是 "参见" 或 "对照"。它通常用于表达对物种身份的不确定性，暗示该物种可能是某个已知物种的近似或相关类型，但不能确定其确切身份。

当一个生物学家在研究中遇到一个物种，其特征或特性与某个已知的物种非常相似，但由于某种原因不能确切地确定其分类时，可能会使用 "cf." 来表示这种不确定性。这样做有助于提醒读者或其他研究者，该物种的身份存在一定程度的猜测或推测。

举个例子，假设一个生物学家在野外发现了一种类似于已知物种 "Species A" 的动物，但某些特征略有差异，无法确定是否属于同一物种。在这种情况下，可以使用 "cf. Species A" 来表示这个物种与 "Species A" 相似，但存在一定的不确定性。

# aff.

在生物学分类学中，物种学名中出现 "aff." 表示一种近似的关系或亲缘关系。这个缩写来自拉丁文 "affinis"，意思是 "相似" 或 "有关联"。它通常用于表示该物种与已知物种有某种相似性，但尚未确定其确切的分类位置。

当一个生物学家在研究中遇到一个物种，其特征或特性与某个已知的物种非常相似，但由于某种原因不能确定其确切身份，或者认为该物种与已知物种有某种关联时，可能会使用 "aff." 来表示这种近似的关系。

举个例子，假设一个生物学家在野外发现了一种植物，其形态和生态特征与已知物种 "Species A" 非常相似，但在一些细节上有所不同。在这种情况下，可以使用 "Species A aff." 来表示这个物种与 "Species A" 有某种相似性，但尚未确切确定其是否属于同一物种。

**英文名词对应如下：**

- `genus`: 属（一种分类等级，用于表示生物学中属的概念）
- `species`: 种（生物学中表示一个独立的生物种类）
- `no rank`: 无等级（表示没有特定的分类等级）
- `varietas`: 变种（生物学中表示种内的变异类型）
- `strain`: 菌株（微生物学中指特定的细菌、真菌或病毒株系）
- `forma`: 变种（生物学中指种内的特定变异类型）



# tsv-filter

`tsv-filter` 是一个命令行工具，用于按照指定的条件筛选文本文件中的行（记录）。它通常用于处理以制表符（或其他分隔符）分隔的数据，即 TSV（Tab-Separated Values）格式。

`tsv-filter` 命令的基本用法如下：

```
tsv-filter [options] [file]
```

其中，`file` 是要处理的文本文件名。如果不指定文件名，则 `tsv-filter` 将从标准输入读取数据。

常用选项：

- `--eq <field>:<value>`：仅保留字段 `<field>` 等于 `<value>` 的行。
- `--ne <field>:<value>`：仅保留字段 `<field>` 不等于 `<value>` 的行。
- `--gt <field>:<value>`：仅保留字段 `<field>` 大于 `<value>` 的行。
- `--lt <field>:<value>`：仅保留字段 `<field>` 小于 `<value>` 的行。
- `--ge <field>:<value>`：仅保留字段 `<field>` 大于等于 `<value>` 的行。
- `--le <field>:<value>`：仅保留字段 `<field>` 小于等于 `<value>` 的行。
- `--str-eq <field>:<value>`：仅保留字段 `<field>` 的值等于 `<value>` 的行（按字符串比较）。
- `--str-ne <field>:<value>`：仅保留字段 `<field>` 的值不等于 `<value>` 的行（按字符串比较）。
- `--str-in-fld <field>:<file>`：仅保留字段 `<field>` 的值在指定文件 `<file>` 中出现的行。

`tsv-filter` 可以根据数据的特定字段进行筛选，保留满足条件的行，并将结果输出到标准输出或指定的输出文件中。它非常适用于处理大规模的数据集，以及在命令行中处理数据的需求。



# tsv-select
`tsv-select`命令用于选择TSV（Tab Separated Values）文件中的特定列或行。它可以根据列名或列索引选择列，也可以使用条件表达式选择行。

下面是`tsv-select`命令的基本语法：

```
tsv-select [OPTIONS] [FILE]
```

其中，`OPTIONS`是可选的命令行选项，`FILE`是要选择的TSV文件。

常用的选项包括：

- `-c, --columns`：指定要选择的列，可以是单个列或多个列，多个列之间使用逗号分隔。可以使用列名或列索引。
- `-r, --rows`：指定要选择的行，可以使用条件表达式进行选择。
- `-H, --header`：指定输入文件包含列名行。
- `-o, --output`：指定输出文件的路径。
- `-f, --fields <field1,field2,...>`: 指定要选择的字段名列表。

以下是一些示例：

- `tsv-select -c name,age input.tsv`：选择`name`列和`age`列。
- `tsv-select -c 1-3 input.tsv`：选择第1列到第3列。
- `tsv-select -r "age > 18" input.tsv`：选择满足条件`age > 18`的行。
- `tsv-select -H -c name,age -o output.tsv input.tsv`：选择`name`列和`age`列，并将结果保存到`output.tsv`文件中。

综上所述，`tsv-select`命令可以根据指定的列或行选择TSV文件中的数据，并可以将结果输出到指定的文件中。


# tsv-sort
`tsv-sort`命令是用于对TSV（Tab Separated Values）文件进行排序的命令。它可以按照指定的列或多个列进行排序，并可以选择升序或降序排列。

下面是`tsv-sort`命令的基本语法：

```
tsv-sort [OPTIONS] [FILE]
```

其中，`OPTIONS`是可选的命令行选项，`FILE`是要排序的TSV文件。

常用的选项包括：

- `-k, --key`：指定要排序的列，可以是单个列或多个列，多个列之间使用逗号分隔。
- `-r, --reverse`：按照降序排列，默认是升序排列。
- `-H, --header`：指定输入文件包含列名行。
- `-o, --output`：指定输出文件的路径。

以下是一些示例：

- `tsv-sort -k 2 input.tsv`：按照第2列进行升序排列。
- `tsv-sort -k 3,4 -r input.tsv`：按照第3列和第4列进行降序排列。
- `tsv-sort -H -k name -o output.tsv input.tsv`：按照`name`列进行升序排列，并将结果保存到`output.tsv`文件中。

综上所述，`tsv-sort`命令可以根据指定的列对TSV文件进行排序，并可以选择升序或降序排列。


# tsv-summarize
`tsv-summarize`命令用于对TSV（Tab Separated Values）文件进行汇总统计。它可以计算每列的统计指标，如计数、求和、平均值、最大值、最小值等。

下面是`tsv-summarize`命令的基本语法：

```
tsv-summarize [OPTIONS] [FILE]
```

其中，`OPTIONS`是可选的命令行选项，`FILE`是要汇总统计的TSV文件。

常用的选项包括：

- `-c, --columns`：指定要汇总统计的列，可以是单个列或多个列，多个列之间使用逗号分隔。可以使用列名或列索引。
- `-H, --header`：指定输入文件包含列名行。
- `-o, --output`：指定输出文件的路径。

以下是一些示例：

- `tsv-summarize -c age input.tsv`：计算`age`列的统计指标。
- `tsv-summarize -c 2-4 input.tsv`：计算第2列到第4列的统计指标。
- `tsv-summarize -H -c name,age -o output.tsv input.tsv`：计算`name`列和`age`列的统计指标，并将结果保存到`output.tsv`文件中。

综上所述，`tsv-summarize`命令可以对指定的列进行统计汇总，并可以将结果输出到指定的文件中。



# sed
`sed` 是一个流编辑器，用于在文本中进行查找和替换操作。要在 `sed` 中替换字符，可以使用 `s` 命令，其语法如下：

```
sed 's/要替换的字符/替换后的字符/g'
```

其中：
- `s`：表示替换操作。
- `/要替换的字符/`：表示要被替换的字符或字符串。可以使用正则表达式来匹配更复杂的模式。
- `替换后的字符`：表示替换后的字符或字符串。
- `g`：表示全局替换，即对每一行中匹配的所有地方都进行替换。如果不加 `g`，只会替换每行中第一次匹配的地方。

例如，假设有一个文本文件 `example.txt` 包含以下内容：

```
Hello, world!
Hello, Sed!
```

要将其中的 "Hello" 替换为 "Hi"，可以使用以下 `sed` 命令：

```
sed 's/Hello/Hi/g' example.txt
```

执行以上命令后，输出将是：

```
Hi, world!
Hi, Sed!
```

请注意，`sed` 命令默认将结果输出到标准输出（屏幕）。如果要在原始文件中进行替换操作，可以使用 `-i` 选项：

```
sed -i 's/Hello/Hi/g' example.txt
```

这将直接在 `example.txt` 中进行替换，不会在标准输出显示结果。



# tsv-join
`tsv-join` 是一个用于合并 TSV（Tab-Separated Values）格式文件的命令行工具，它可以根据指定的字段进行连接操作。

以下是 `tsv-join` 命令的基本用法：

```
tsv-join [选项] -f <join-file> -k <key-field> -d <data-field> [文件]
```
```
tsv-join --help
Synopsis: tsv-join --filter-file file [options] [file...]

tsv-join matches input lines (the 'data stream') against lines from a
'filter' file. The match is based on individual fields or the entire
line. Fields can be specified either by field number or field name.
Use '--help-verbose' for details.

Options:

           --help-verbose               Print full help.
            --help-fields               Print help on specifying fields.
-f          --filter-file FILE          (Required) File with records to use as a filter.
-k           --key-fields <field-list>  Fields to use as join key. Default: 0 (entire line).
-d          --data-fields <field-list>  Data stream fields to use as join key, if different than --key-fields.
-a        --append-fields <field-list>  Filter file fields to append to matched data stream records.
-H               --header               Treat the first line of each file as a header.
-p               --prefix STR           String to use as a prefix for --append-fields when writing a header line.
-w            --write-all STR           Output all data stream records. STR is the --append-fields value when writing unmatched records.
-e              --exclude               Exclude matching records.
              --delimiter CHR           Field delimiter. Default: TAB. (Single byte UTF-8 characters only.)
-z --allow-duplicate-keys               Allow duplicate keys with different append values (last entry wins).
-V              --version               Print version information and exit.
-h                 --help This help information.
```

- `join-file`：指定用于连接的第二个文件，它是另一个 TSV 格式文件。
- `key-field`：指定用于连接的字段在第一个文件中的列索引。
- `data-field`：指定用于连接的字段在第二个文件中的列索引。
- `[文件]`：可选，用于指定要连接的第一个文件。如果未指定，则从标准输入中读取数据。

下面是一些常用的选项：

  - `-e`：反向匹配。
  - `-m`：指定连接操作的方式。可以是 `1`, `2`, `a`, `b` 或 `o`。默认为 `1`，表示只输出两个文件中都有的行。其他选项含义如下：
  - `1`: 只输出 `join-file` 中匹配的行。
  - `2`: 只输出第一个文件中匹配的行。
  - `a`: 输出两个文件中所有的行，不论是否匹配。
  - `b`: 只输出两个文件中都有的行，并将非匹配行的值设置为空。
  - `o`: 输出两个文件中所有的行，并将非匹配行的值设置为空。
  - `-i`：忽略大小写进行连接。

以下是一个示例，假设有两个 TSV 文件 `file1.tsv` 和 `file2.tsv`：

`1.tsv` 内容：

```
1       8
2       9
3       10
4       11
```
`2.tsv` 内容：
```
6       8
5       4
3       12
4       11
```
**example：**

把两个文件的第一列进行匹配
```
tsv-join -f 1.tsv -k 1 2.tsv
3       12
4       11
```
把1.tsv第一列和2.tsv第二列进行匹配
```
tsv-join -f 1.tsv -k 1 -d 2 2.tsv
5       4
```
反向匹配
```
tsv-join -f 1.tsv -k 1 -d 2 -e 2.tsv
6       8
3       12
4       11
```
把2.tsv的第2列添加到后面
```
tsv-join -f 1.tsv -k 1 -d 2 -a 2 2.tsv
5       4       11
```
把2.tsv的第1列添加到后面
```
tsv-join -f 1.tsv -k 1 -d 2 -a 1 2.tsv
5       4       4
```

# N50    GPT计算方法有疑问
"N50" 是一个常用的生物信息学中的统计指标，用于衡量基因组装（genome assembly）或序列集合（sequence dataset）的质量。

N50 是指在按长度降序排列后的序列集合中，前 50% 的总长度所包含的最长的连续序列长度。换句话说，N50 是将序列按长度从大到小排序后，从最长的序列开始累加，直到累计长度达到总长度的一半。N50 值越大，表示集合中的长序列比较多，说明序列集合的质量较高。

例如，一个序列集合包含如下长度的序列：

100, 150, 200, 250, 300, 350, 400

按长度降序排列后：

400, 350, 300, 250, 200, 150, 100

计算 N50 的过程为：

1. 总长度为 100 + 150 + 200 + 250 + 300 + 350 + 400 = 1750
2. N50 = 第一个序列 400，因为它的长度是总长度的一半。       ？有点疑问

所以，对于这个序列集合，N50 的值为 400。

在基因组装中，较高的 N50 值通常表示较长的连续序列，提供更好的基因组信息。因此，N50 是衡量基因组装质量的重要指标。


https://blog.csdn.net/u010608296/article/details/102771217


# rsync
`rsync -avP` 是一个用于文件同步和传输的常用命令。它的主要功能是在本地或远程两个主机之间复制文件和目录，并具有以下参数的含义：
`rsync` 命令的基本语法如下：

```
rsync [options] source destination
```

- `source`: 源文件或目录，表示要复制的数据的来源。可以是本地路径，也可以是远程路径。
- `destination`: 目标文件或目录，表示要将数据复制到的位置。同样可以是本地路径或远程路径。

常用的 `rsync` 命令选项包括：

- `-a, --archive`：归档模式，保留文件的权限、所有者信息、时间戳等。
- `-v, --verbose`：详细模式，显示传输的文件列表和进度。
- `-P`：组合了 `--progress` 和 `--partial` 选项，显示实时传输进度并允许断点续传。
- `-r, --recursive`：递归复制，复制源目录及其子目录中的所有文件和目录。
- `-u, --update`：仅复制源目录中较新的文件到目标目录。
- `--delete`：删除目标目录中不在源目录中的文件。

以下是一些 `rsync` 命令示例：

1. 将本地目录的内容复制到另一个本地目录中：
   ```
   rsync -av /path/to/source_directory/ /path/to/destination_directory/
   ```

2. 将本地目录的内容复制到远程服务器上：
   ```
   rsync -av /path/to/source_directory/ username@remote_server:/path/to/destination_directory/
   ```

3. 从远程服务器复制文件到本地：
   ```
   rsync -av username@remote_server:/path/to/source_file /path/to/local_directory/
   ```

在本地账号输入, 把`.nwr`中的文件下载到本地文件夹`.nwr`中
```
rsync -avP wangq@202.119.37.251:~/.nwr/ /home/guoqinghua/.nwr/
```

把超算上的文件下载到了`~`根目录中
```
rsync -avP wangq@202.119.37.251:~/.nwr/ /home/guoqinghua/
```


4. 从本地复制文件到远程服务器：
   ```
   rsync -av /path/to/source_file username@remote_server:/path/to/destination_directory/
   ```

5. 使用 `--delete` 选项同步源目录和目标目录，并删除目标目录中不存在于源目录的文件：
   ```
   rsync -av --delete /path/to/source_directory/ /path/to/destination_directory/
   ```

这将通过 ssh 连接将数据传输到远程主机。其中 `remote_username` 是远程主机的用户名，`remote_host` 是远程主机的主机名或 IP 地址。

注意：使用 `rsync` 命令时，请确保目标路径的末尾是否带有斜杠 `/`，它决定了文件复制的行为。如果目标路径末尾带有斜杠，则会将源路径的内容复制到目标路径下；如果目标路径末尾不带斜杠，则会将源路径的内容复制到目标路径下的一个新目录中。  

# for循环
在 Bash 脚本中，`for` 循环用于迭代处理一系列值，例如数组元素、文件列表等。`for` 循环的基本语法如下：

```bash
for var in list
do
    # 循环体
done
```

其中，`var` 是一个变量名，用于存储循环迭代的值。`list` 是要迭代的一系列值，可以是用空格分隔的单词列表，也可以是一个数组的元素列表，或者是一个命令的输出结果。

`for` 循环会依次将 `list` 中的值赋给 `var`，并执行循环体中的代码块。每次迭代，`var` 的值都会更新为 `list` 中的下一个元素，直到所有值都被处理完毕。

以下是一些 `for` 循环的示例：

1. 迭代数组元素：
```bash
fruits=("apple" "banana" "orange" "grape")

for fruit in "${fruits[@]}"
do
    echo "I like $fruit"
done
```

2. 迭代文件列表：
```bash
for file in *.txt
do
    echo "Processing file: $file"
    # 在这里添加文件处理的代码
done
```

3. 使用命令输出结果作为迭代值：
```bash
for number in $(seq 1 5)
do
    echo "Number: $number"
done
```

在以上示例中，`for` 循环依次迭代数组 `fruits` 中的元素、当前目录下的所有 `.txt` 文件、以及 `seq 1 5` 命令输出的数字。在每次循环中，`fruit`、`file` 和 `number` 分别存储着数组元素、文件名和数字，并在循环体中进行相应的处理。


# cut
`cut` 是一个用于从文本文件中截取列（字段）的命令。它通常用于从文件或标准输入中选择指定列并输出。`cut` 命令的基本语法如下：

```
cut OPTION... [FILE]
```

其中 `OPTION` 是一系列选项，用于指定要截取的列和其他参数。`FILE` 是要处理的输入文件的名称，如果不指定文件名，则 `cut` 命令将从标准输入中读取数据。

`cut` 命令支持以下常用的选项：

- `-f list`: 指定要截取的列，`list` 是用逗号分隔的列号或列范围。例如，`-f 1,3,5` 表示截取第 1、第 3 和第 5 列，`-f 2-4` 表示截取第 2 到第 4 列。

- `-d delim`: 指定字段分隔符（delimiter），默认为制表符 `\t`。可以通过该选项指定其他分隔符。

- `--output-delimiter=STRING`: 指定输出字段分隔符，用于在输出中分隔字段。

- `-s`: 忽略不包含分隔符的行。

下面是一些常见的示例：

1. 从文件中截取指定列并输出：
   ```
   cut -f 2,4,6 input.txt
   ```

2. 从标准输入中读取数据，并截取第 3 列和第 5 列，使用逗号作为分隔符，并输出结果到标准输出：
   ```
   cat input.txt | cut -d ',' -f 3,5
   ```

3. 从文件中截取指定列，并使用冒号作为输出字段的分隔符：
   ```
   cut -f 2-5 --output-delimiter=":" input.txt
   ```

# SQLite
SQLite 是一种轻量级的嵌入式关系型数据库，其查询语句的语法结构与标准 SQL 类似。SQLite 支持多种查询类型，包括 SELECT、INSERT、UPDATE、DELETE 等，以下是 SQLite SELECT 查询语句的基本语法结构：

```sql
SELECT column1, column2, ...
FROM table_name
[WHERE condition]
[GROUP BY column1, column2, ...]
[HAVING condition]
[ORDER BY column1 [ASC|DESC], column2 [ASC|DESC], ...]
[LIMIT number OFFSET offset];
```

- `SELECT`: 关键字，表示开始一个 SELECT 查询语句。
- `column1, column2, ...`: 要查询的列名或表达式，用逗号分隔。可以使用 `*` 表示查询所有列。
- `FROM`: 关键字，表示查询的数据来源，即要查询的表名。
- `WHERE`: 可选关键字，用于指定查询的条件。条件是一个逻辑表达式，用于筛选满足条件的记录。
- `GROUP BY`: 可选关键字，用于对结果进行分组。通常结合聚合函数使用。
- `HAVING`: 可选关键字，用于对 GROUP BY 分组结果进行条件过滤。
- `ORDER BY`: 可选关键字，用于对查询结果进行排序，默认为升序。可以指定多个列名进行多级排序。
- `LIMIT`: 可选关键字，用于限制查询结果返回的记录数。
- `OFFSET`: 可选关键字，用于指定查询结果的偏移量，即从第几条记录开始返回结果。

注意事项：
- SQL 关键字一般用大写表示，但在 SQLite 中不区分大小写，因此 SELECT、select 或 Select 都是合法的。
- 在查询语句中，使用分号 `;` 结束语句，但在 SQLite 的命令行交互模式下，可以省略分号。

下面是一个示例 SELECT 查询语句：

```sql
SELECT id, name, age
FROM students
WHERE age > 18
ORDER BY age DESC
LIMIT 10;
```

该查询语句从名为 `students` 的表中查询满足条件 `age > 18` 的记录，并按照 `age` 列进行降序排序，最多返回前 10 条记录。

## 超算使用
超算 ssh wangq@202.119.37.251

yes  密码

Ctrl+D快捷键，退出登录。

## mv
Linux mv（英文全拼：move file）命令用来为文件或目录改名、或将文件或目录移入其它位置。

将文件 aaa 改名为 bbb :
```
mv aaa bbb
```

将 info 目录放入 logs 目录中。注意，如果 logs 目录不存在，则该命令将 info 改名为 logs。
```
mv info/ logs 
```

再如将 /usr/runoob 下的所有文件和目录移到当前目录下，命令行为：
```
$ mv /usr/runoob/*  . 
```


## 处理目录的常用命令

- ls（英文全拼：list files）: 列出目录及文件名
- cd（英文全拼：change directory）：切换目录
- pwd（英文全拼：print work directory）：显示目前的目录
- mkdir（英文全拼：make directory）：创建一个新的目录
- rmdir（英文全拼：remove directory）：删除一个空的目录
- cp（英文全拼：copy file）: 复制文件或目录
- rm（英文全拼：remove）: 删除文件或目录
- mv（英文全拼：move file）: 移动文件与目录，或修改文件与目录的名称

## Linux 文件内容查看

- cat  由第一行开始显示文件内容
- tac  从最后一行开始显示，可以看出 tac 是 cat 的倒着写！
- nl   显示的时候，顺道输出行号！
- more 一页一页的显示文件内容
- less 与 more 类似，但是比 more 更好的是，他可以往前翻页！
- head 只看头几行
- tail 只看尾巴几行

# tar
用于打包、压缩和归档文件的命令行工具。它可以将多个文件或目录打包成一个单独的文件，并可选地对其进行压缩，以减少文件的大小。`tar` 命令的基本语法如下：

```
tar [选项] [目标文件] [文件或目录...]
```

常用的 `tar` 命令选项包括：

- `-c, --create`：创建一个新的 tar 文件。
- `-x, --extract`：从 tar 文件中解压文件。
- `-t, --list`：列出 tar 文件中包含的文件列表。
- `-v, --verbose`：显示详细的操作信息。
- `-f, --file <文件>`：指定要操作的 tar 文件的名称。
- `-z, --gzip`：使用 gzip 压缩算法压缩或解压缩 tar 文件，通常文件名以 `.tar.gz` 或 `.tgz` 结尾。
- `-j, --bzip2`：使用 bzip2 压缩算法压缩或解压缩 tar 文件，通常文件名以 `.tar.bz2` 或 `.tbz2` 结尾。
- `-C <目录>`：切换到指定目录，然后执行操作。用于在指定目录中解压文件。

以下是一些常见的 `tar` 命令示例：

1. 创建一个新的 tar 文件：
   ```
   tar -cvf archive.tar file1.txt file2.txt dir1/
   ```

2. 解压缩 tar 文件：
   ```
   tar -xvf archive.tar
   ```

3. 使用 gzip 压缩 tar 文件：
   ```
   tar -czvf archive.tar.gz file1.txt file2.txt dir1/
   ```

4. 使用 bzip2 压缩 tar 文件：
   ```
   tar -cjvf archive.tar.bz2 file1.txt file2.txt dir1/
   ```

5. 列出 tar 文件中包含的文件列表：
   ```
   tar -tvf archive.tar
   ```

# touch
当使用 `touch` 命令时，如果指定的文件已经存在，`touch` 命令会更新该文件的访问时间和修改时间，而不会更改文件的内容。如果指定的文件不存在，`touch` 命令会创建一个空文件。

https://www.runoob.com/linux/linux-comm-touch.html

# find
`find` 命令用于在指定目录下搜索文件和目录。它是一个非常强大且灵活的工具，可用于执行各种搜索操作。以下是 `find` 命令的常用参数：

- `路径`: 指定要搜索的起始目录路径。
- `-type`: 指定要搜索的文件类型。
  - `-type f`: 搜索常规文件。
  - `-type d`: 搜索目录。
  - `-type l`: 搜索符号链接。
- `-name`: 按文件名进行搜索，可以使用通配符来匹配文件名模式。
- `-iname`: 类似于 `-name`，但是忽略文件名的大小写。
- `-user`: 按拥有者用户名搜索文件。
- `-group`: 按所属组搜索文件。
- `-size`: 按文件大小搜索。可以使用`+`表示大于，`-`表示小于，不加符号表示等于指定大小。
- `-mtime`: 按文件修改时间搜索。可以使用`+`表示更早，`-`表示更近，不加符号表示恰好指定天数前的文件。
- `-maxdepth` 和 `-mindepth`: 限制搜索的最大和最小深度，即相对于起始目录的层次深度。
- `-prune`: 排除指定目录，不在其下搜索。
- `-exec`: 对搜索到的每个文件执行指定的命令。
- `-delete`: 删除搜索到的文件。
- `-print`: 将搜索到的文件输出到标准输出。

# echo
"echo" 命令在命令行中用于将文本输出到标准输出（通常是终端屏幕）。它是一种简单而常用的命令，特别用于输出一些消息、变量值或调试信息。

基本的 "echo" 命令语法如下：

```
echo [options] [string]
```

常用的 "echo" 命令参数包括：

- `-n`: 不输出结尾的换行符。
- `-e`: 解释特定的转义序列。
- `-E`: 不解释特定的转义序列（默认行为）。
- `-c`: 不换行，输出到同一行。

# xargs
xargs（英文全拼： eXtended ARGuments）是给命令传递参数的一个过滤器，也是组合多个命令的一个工具。

xargs 可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据。

xargs 也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行变多行。

xargs 默认的命令是 echo，这意味着通过管道传递给 xargs 的输入将会包含换行和空白，不过通过 xargs 的处理，换行和空白将被空格取代。

xargs 是一个强有力的命令，它能够捕获一个命令的输出，然后传递给另外一个命令。

之所以能用到这个命令，关键是由于很多命令不支持|管道来传递参数，而日常工作中有有这个必要，所以就有了 xargs 命令，例如：
```
find /sbin -perm +700 |ls -l       #这个命令是错误的
find /sbin -perm +700 |xargs ls -l   #这样才是正确的
```

详细介绍在菜鸟教程[https://www.runoob.com/linux/linux-comm-xargs.html]


`xargs` 命令的基本语法是：

```
xargs [options] [command]
```

其中，`options` 是一些可选的参数，用于控制 `xargs` 的行为，而 `command` 是要执行的命令。如果未指定 `command`，则 `xargs` 默认会将数据作为参数传递给 `echo` 命令，并将其输出到标准输出。

常用的 `xargs` 参数包括：

- `-d delimiter`: 指定输入数据的分隔符。默认情况下，`xargs` 使用空格和换行符作为分隔符。
- `-I replstr`: 指定替换字符串，用于在命令中替换输入的数据。
- `-n num`: 指定每次执行命令时传递给命令的参数个数。
- `-t`: 在执行命令之前，先将要执行的命令打印输出到标准错误。
- `-p`: 在执行命令之前，询问用户是否要继续执行。
- `-r`: 当标准输入为空时，不执行命令。
- `-s num`: 指定每个参数的最大长度。
- `-L num`: 指定每次从标准输入读取的行数。

`xargs` 的用法通常是与其他命令和管道结合使用，以处理来自标准输入的数据，并将数据作为参数传递给其他命令。它可以显著简化一些复杂的批处理任务。注意，在使用 `xargs` 时，要注意输入数据的格式和命令的要求，确保它们匹配正确，以避免出现意外的结果。


# datamash
`datamash` 是一个用于文本数据处理的命令行工具，它可以执行各种统计计算和数据操作。`datamash` 命令在GNU coreutils的datamash软件包中提供。

以下是一些常见的 `datamash` 命令参数：

1. **数据操作参数**：
   - `groupby <field>`: 根据指定的字段对数据进行分组。
   - `sort`: 对数据进行排序。
   - `reverse`: 反转排序顺序。
   - `unique`: 去除重复的行。
   - `dedup`: 同 `unique`，去除重复的行。
   - `count`: 计算行数。
   - `sum <field>`: 对指定字段进行求和。
   - `mean <field>`: 对指定字段计算平均值。
   - `median <field>`: 对指定字段计算中位数。
   - `min <field>`: 找出指定字段的最小值。
   - `max <field>`: 找出指定字段的最大值。
   - `stdev <field>`: 对指定字段计算样本标准偏差。
   - `pvar <field>`: 对指定字段计算样本方差。
   - `pvar`: 对所有字段计算样本方差。

2. **输入输出参数**：
   - `-H`: 在输出中不显示头部。
   - `-T <char>`: 设置字段分隔符。
   - `-s <char>`: 设置记录分隔符。
   - `-W`: 对宽格式输入进行处理。
   - `-f <file>`: 从指定文件读取命令行参数。

3. **其他参数**：
   - `--version`: 显示软件版本信息。
   - `--help`: 显示帮助信息。

`datamash` 可以根据具体的数据处理需求，结合不同的参数来执行各种统计和数据操作。它对于处理文本数据集合非常有用，并且支持多种聚合操作，让数据分析和统计更加便捷。您可以通过 `man datamash` 命令查看完整的 `datamash` 命令手册以获取更多详细信息。


# eval
`eval` 是一个在shell脚本中使用的命令，用于将字符串作为命令进行解析和执行。

当使用`eval`命令时，它会将传递给它的参数当作一个命令进行解析，并在当前shell环境中执行该命令。

例如，假设有一个变量`command="ls -l"`，通过执行`eval $command`，实际上会将字符串`ls -l`解析为`ls -l`命令，并在当前shell中执行该命令，显示当前目录的详细列表。

`eval`命令的使用需要谨慎，因为它会将字符串中的特殊字符和元字符进行解析和处理，这可能导致意外的结果或安全问题。在使用`eval`时，应确保传递给它的字符串是可信的，并且避免使用来自不可信来源的字符串。



# if条件判断
`[[`和`]]`是Shell脚本中的条件判断语法，用于进行条件判断和比较操作。

`[[ expression ]]`的作用是对`expression`进行条件判断，如果`expression`为真，则条件成立。

`[[`和`]]`之间的`expression`可以包含以下类型的条件判断和比较操作：

- 字符串比较：`==`（相等）、`!=`（不相等）、`=~`（匹配正则表达式）、`<`（小于）和 `>`（大于）。
- 数值比较：`-eq`（等于）、`-ne`（不等于）、`-lt`（小于）、`-le`（小于等于）、`-gt`（大于）和 `-ge`（大于等于）。
- 逻辑操作：`&&`（逻辑与）、`||`（逻辑或）、`!`（逻辑非）。

例如，下面是一些示例用法：

```shell
if [[ $var == "abc" ]]; then
    echo "变量 var 的值为 abc"
fi

if [[ $num -gt 10 && $num -lt 20 ]]; then
    echo "变量 num 的值大于 10，且小于 20"
fi

if [[ $str =~ ^[0-9]+$ ]]; then
    echo "变量 str 是一个由数字组成的字符串"
fi
```

在条件判断中，`[[`和`]]`提供了更丰富的功能，可以进行更复杂的条件判断和比较操作，同时还支持字符串和变量的引用，以及正则表达式的匹配。与`[`和`]`相比，`[[`和`]]`更常用，并且在处理字符串时更灵活。


# mash triangle
`mash triangle` 是 `Mash` 工具的一个子命令，用于生成基于输入样本的距离矩阵。距离矩阵用于衡量样本之间的相似性或差异性。以下是 `mash triangle` 命令的常见参数：

- `-h`, `--help`: 显示命令的帮助信息，包括参数说明和使用示例。

- `-p <threads>`, `--threads <threads>`: 指定要使用的线程数。例如，`-p 8` 表示使用 8 个线程进行计算。

- `-k <kmer_size>`, `--kmer <kmer_size>`: 指定要使用的 k-mer 大小，用于生成距离矩阵。例如，`-k 21` 表示使用 k-mer 大小为 21。

- `-l <list_file>`, `--list <list_file>`: 指定一个包含要计算距离的样本文件列表。每一行包含一个样本的路径。可以使用 `-l` 参数来提供这个列表。

- `-o <output_file>`, `--output <output_file>`: 指定输出文件的名称。生成的距离矩阵将写入这个文件中。

- `-E`, `--full`: 生成一个完整的距离矩阵，其中包含了样本之间的所有距离信息。这个矩阵是一个对称矩阵，包括对角线。

- `-I <input_file>`, `--input <input_file>`: 指定输入的 mash sketch 文件，用于计算样本之间的距离。可以通过这个参数指定一个草图文件，而不是使用 `-l` 参数来提供样本列表。

- `-s <sample_size>`, `--sample-size <sample_size>`: 指定要从每个样本中随机选择的 k-mer 数量。这个值会影响距离矩阵的计算速度和准确性。

- 其他参数：还有其他一些参数用于调整计算的细节，如 `-r` 用于在计算中使用稀疏哈希表。

示例用法：
```bash
mash triangle -p 8 -k 21 -l sample_list.txt -o distance_matrix.tsv
```

这将使用 8 个线程，k-mer 大小为 21，在样本列表文件 `sample_list.txt` 中列出的样本之间生成一个距离矩阵，并将结果保存到 `distance_matrix.tsv` 文件中。

# mash sketch
`mash sketch` 是 `Mash` 工具的一个子命令，用于生成一个草图（sketch），该草图可用于后续的比较和分析操作。草图是一种用于表示基因组数据的紧凑数据结构，可以快速计算样本之间的相似性。以下是 `mash sketch` 命令的常见参数：

- `-h`, `--help`: 显示命令的帮助信息，包括参数说明和使用示例。

- `-p <threads>`, `--threads <threads>`: 指定要使用的线程数。例如，`-p 8` 表示使用 8 个线程进行计算。

- `-k <kmer_size>`, `--kmer <kmer_size>`: 指定要使用的 k-mer 大小，用于生成草图。例如，`-k 21` 表示使用 k-mer 大小为 21。

- `-s <sample_size>`, `--sample-size <sample_size>`: 指定要从输入数据中随机选择的 k-mer 数量，以构建草图。这个值会影响草图的大小和计算速度。

- `-m <hash_size>`, `--min-hashes <hash_size>`: 指定草图中的最小哈希数。草图中的哈希数越多，草图的精度越高，但草图的大小也会增加。

- `-r`, `--r-mode`: 启用“r-mode”，这会使用稀疏哈希表来降低草图的内存占用。适用于处理大规模数据。

- `-I <identifier>`, `--identifier <identifier>`: 指定输入数据的标识符，用于在生成草图时标记样本。

- `-o <output_file>`, `--output <output_file>`: 指定输出草图文件的名称。

- `<input_files>`: 输入基因组数据文件的路径。可以指定一个或多个输入文件，用于构建草图。

示例用法：
```bash
mash sketch -p 8 -k 21 -s 100000 -m 100 genome1.fasta genome2.fasta -o output.msh
```

这将使用 8 个线程，k-mer 大小为 21，从输入文件 `genome1.fasta` 和 `genome2.fasta` 中随机选择 100,000 个 k-mer，生成一个包含最少 100 个哈希的草图，并将结果保存到 `output.msh` 文件中。